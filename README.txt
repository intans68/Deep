ВСЕМ ПРИВЕТ.


Суть идеи проста. При при помощи модуля diff из библиотеки Sympy автоматизируем процесс нахождения формул частных производных!!! По полученным формулам вычисляем поправки и осущаствяем градиентый спуск.

- Имеются функции активации: Sigmoid (Сигмода) и Tahn(Гиперболический тангенс). Легко добавить любые другие.
- 1 функция потерь (квадратичная). Легко добавить другие.
- Имеется небольшая оптимизация Learning Rate.

ГЛАВНЫЙ МИНУС ! Не реализован алгоритм обратного распространения ошибки !!! (

Sympy поддерживает numpy-массивы, но проиводительность низкая из-за однопоточных рассчетов.

В данном виде проект совершенно не доработан. ПРОШУ ПРОЩЕНИЯ !